{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Mr.\n",
      "[nltk_data]     Luke\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Id  AcceptedAnswerId  AnswerCount  \\\n",
      "1         25277             25456            3   \n",
      "7         44391             65953           12   \n",
      "20        62999                 0            9   \n",
      "47       138261            138792            9   \n",
      "51       139046            139500            7   \n",
      "...         ...               ...          ...   \n",
      "53339  67746074          67754768            1   \n",
      "53340  67746075                 0            0   \n",
      "53341  67750181                 0            0   \n",
      "53347  67754483                 0            1   \n",
      "53348  67754484                 0            0   \n",
      "\n",
      "                                                    Body  \\\n",
      "1      <p>There is a <a href=\"http://stackoverflow.us...   \n",
      "7      <p>This is related to <a href=\"https://stackov...   \n",
      "20     <p>Iâ€™ve been trying to install Ms SQL Server 2...   \n",
      "47     <p>I am having a table Table1 with columns id1...   \n",
      "51     <p>I need to write code that picks up PGP-encr...   \n",
      "...                                                  ...   \n",
      "53339  <p>I have a webassembly project, and I want to...   \n",
      "53340  <p><a href=\"https://practice.geeksforgeeks.org...   \n",
      "53341  <p>I'm trying to use node-7z in my Electron ap...   \n",
      "53347  <p>I have stumbled over <a href=\"https://www.c...   \n",
      "53348  <p>What can I do to resolve this problem?</p>\\...   \n",
      "\n",
      "                    ClosedDate  CommentCount       CommunityOwnedDate  \\\n",
      "1                          NaN             1                      NaN   \n",
      "7                          NaN             0                      NaN   \n",
      "20                         NaN             4                      NaN   \n",
      "47                         NaN             1  2008-09-26 08:16:31.700   \n",
      "51                         NaN             1                      NaN   \n",
      "...                        ...           ...                      ...   \n",
      "53339                      NaN             0                      NaN   \n",
      "53340  2021-05-28 22:38:42.077             8                      NaN   \n",
      "53341                      NaN             2                      NaN   \n",
      "53347                      NaN             1                      NaN   \n",
      "53348  2021-05-29 18:17:09.747             0                      NaN   \n",
      "\n",
      "                  CreationDate  FavoriteCount         LastActivityDate  \\\n",
      "1      2008-08-24 18:47:16.197              0  2008-11-17 21:49:56.230   \n",
      "7      2008-09-04 18:23:22.093              9  2017-02-27 08:38:31.137   \n",
      "20     2008-09-15 13:45:43.507              1  2015-12-20 20:26:33.750   \n",
      "47     2008-09-26 08:16:31.700              0  2013-05-22 06:45:24.220   \n",
      "51     2008-09-26 12:15:14.317              1  2010-04-01 01:01:08.450   \n",
      "...                        ...            ...                      ...   \n",
      "53339  2021-05-28 22:28:54.143              0  2021-05-29 18:48:35.737   \n",
      "53340  2021-05-28 22:29:39.317              0  2021-05-28 22:50:29.867   \n",
      "53341  2021-05-29 10:19:08.510              0  2021-05-29 11:13:33.853   \n",
      "53347  2021-05-29 18:10:42.630              1  2021-05-29 20:30:50.837   \n",
      "53348  2021-05-29 18:10:45.843              0  2021-05-29 18:10:45.843   \n",
      "\n",
      "                  LastEditDate LastEditorDisplayName  LastEditorUserId  \\\n",
      "1      2008-11-17 21:49:56.247       Kevin Fairchild              3743   \n",
      "7      2017-05-23 11:53:57.677           Josh Hinman                -1   \n",
      "20     2010-01-11 18:11:55.447        Nigel Campbell              4228   \n",
      "47     2013-05-22 06:45:24.220            balaweblog            208809   \n",
      "51                         NaN                   NaN                 0   \n",
      "...                        ...                   ...               ...   \n",
      "53339                      NaN                   NaN                 0   \n",
      "53340  2021-05-28 22:50:29.867                   NaN            701092   \n",
      "53341  2021-05-29 11:13:33.853                   NaN           2969180   \n",
      "53347  2021-05-29 18:19:07.810                   NaN           1825056   \n",
      "53348                      NaN                   NaN                 0   \n",
      "\n",
      "       OwnerUserId  ParentId  PostTypeId  Score  \\\n",
      "1             2134         0           1      3   \n",
      "7             2527         0           1     16   \n",
      "20               0         0           1      8   \n",
      "47           22162         0           1      4   \n",
      "51           21379         0           1      3   \n",
      "...            ...       ...         ...    ...   \n",
      "53339     12243262         0           1      0   \n",
      "53340     15800903         0           1     -3   \n",
      "53341      2969180         0           1      0   \n",
      "53347      1825056         0           1      0   \n",
      "53348     12255973         0           1     -1   \n",
      "\n",
      "                                                    Tags  \\\n",
      "1      <sql-server-2005><search><full-text-search><fr...   \n",
      "7                        <asp.net><security><encryption>   \n",
      "20     <sql-server><sql-server-2005><installation><se...   \n",
      "47                                 <asp.net><sql-server>   \n",
      "51                <security><ms-access><encryption><pgp>   \n",
      "...                                                  ...   \n",
      "53339                    <c><linker><header><emscripten>   \n",
      "53340            <c++><string><data-structures><hashmap>   \n",
      "53341                    <javascript><node.js><electron>   \n",
      "53347                                    <c++><pointers>   \n",
      "53348                          <mysql><mysql-error-1267>   \n",
      "\n",
      "                                                   Title  ViewCount  \n",
      "1      Can you perform an AND search of keywords usin...       1189  \n",
      "7                       How do I prevent replay attacks?      34825  \n",
      "20      Microsoft SQL Server 2005 service fails to start     106708  \n",
      "47       Select Query in SQL + All the values in columns       5570  \n",
      "51     Easiest way to decrypt PGP-encrypted files fro...      14521  \n",
      "...                                                  ...        ...  \n",
      "53339  How am I supposed to build an emscripten proje...         12  \n",
      "53340          why i am getting \"abc\" instead of \"abaca\"         51  \n",
      "53341  node-7z enoent error 7zip-bin when using password         18  \n",
      "53347  How to assign the pointer of a container eleme...         53  \n",
      "53348                  Illegal mix of collations - MySQL          7  \n",
      "\n",
      "[21402 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('randomPosts.csv', encoding='utf-8')\n",
    "df = df[df['Body'].notna()]\n",
    "\n",
    "df = df[df['PostTypeId'] == 1]\n",
    "\n",
    "df.head()\n",
    "\n",
    "print(df)\n",
    "\n",
    "dict = df.to_dict('index')\n",
    "\n",
    "\n",
    "# for key in dict:\n",
    "    # dict[key]['words_tokenized'] = word_tokenize(dict[key]['Body'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_for_lda(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    # tokens = [token for token in tokens if len(token) > 4]\n",
    "    # tokens = [token for token in tokens if token not in en_stop]\n",
    "    # tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeFirstLastThree(text):\n",
    "    text = text[3:]\n",
    "    # text = text[:3]\n",
    "    text = text[:len(text)-3]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def toLowerCase(text):\n",
    "    text = [word.lower() for word in text]\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "def removeStopWords(text):\n",
    "    stop_words=set(stopwords.words(\"english\"))\n",
    "    filtered_sent=[]\n",
    "    for w in text:\n",
    "        if w not in stop_words:\n",
    "            filtered_sent.append(w)\n",
    "    return filtered_sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "def applyPStemmer(text):\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    stemmed_words=[]\n",
    "    for w in text:\n",
    "        stemmed_words.append(ps.stem(w))\n",
    "\n",
    "    return stemmed_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def applyPStemmer(text):\n",
    "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "    text = tokenizer.tokenize(' '.join(text))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def get_lemma(text):\n",
    "    words = []\n",
    "    for word in text:\n",
    "        lemma = wn.morphy(word)\n",
    "        if (len(word) <= 2 or len(word) >= 15 or word == 'code' or word.isnumeric() or word == 'gt' or word == 'lt' or word =='quot' or word == 'pre' or word == 'amp'):\n",
    "            continue \n",
    "        elif lemma is None or word == lemma:\n",
    "            words.append(word)\n",
    "        else:\n",
    "            words.append(lemma)\n",
    "    return words\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "def get_lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "text_tokens = []\n",
    "i = 0\n",
    "for key in dict:\n",
    "    tokens = prepare_text_for_lda(dict[key]['Body'])\n",
    "    tokens = removeFirstLastThree(tokens)\n",
    "    tokens = toLowerCase(tokens)\n",
    "    tokens = removeStopWords(tokens)\n",
    "    tokens = applyPStemmer(tokens)\n",
    "    tokens = get_lemma(tokens)\n",
    "    # tokens = removeSymbols(tokens)\n",
    "    \n",
    "\n",
    "    # if i < 50:\n",
    "        # print(tokens)\n",
    "    text_tokens.append(tokens)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(118613 unique tokens: ['28sql', 'aspx', 'blockquote', 'com', 'current']...)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "dict_STF = corpora.Dictionary(text_tokens)\n",
    "\n",
    "dictionary = corpora.Dictionary(text_tokens) \n",
    "corpus = [dictionary.doc2bow(text) for text in text_tokens]\n",
    "\n",
    "import pickle\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "dictionary.save('dictionary.gensim')\n",
    "\n",
    "print(dict_STF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_TOPICS = 25\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "ldamodel.save('model5.gensim')\n",
    "topics = ldamodel.print_topics(num_words=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, '0.085*\"name\" + 0.056*\"value\"')\n",
      "(18, '0.022*\"player\" + 0.018*\"device\"')\n",
      "(10, '0.123*\"model\" + 0.076*\"true\"')\n",
      "(3, '0.071*\"version\" + 0.048*\"plugin\"')\n",
      "(23, '0.061*\"step\" + 0.055*\"float\"')\n",
      "(21, '0.109*\"http\" + 0.077*\"com\"')\n",
      "(8, '0.022*\"strong\" + 0.019*\"like\"')\n",
      "(1, '0.055*\"include\" + 0.047*\"int\"')\n",
      "(16, '0.133*\"div\" + 0.132*\"class\"')\n",
      "(9, '0.056*\"int\" + 0.050*\"array\"')\n",
      "(19, '0.060*\"map\" + 0.050*\"product\"')\n",
      "(13, '0.079*\"image\" + 0.069*\"stack\"')\n",
      "(7, '0.049*\"width\" + 0.048*\"color\"')\n",
      "(15, '0.128*\"android\" + 0.044*\"app\"')\n",
      "(2, '0.147*\"java\" + 0.093*\"org\"')\n",
      "(11, '0.053*\"var\" + 0.047*\"script\"')\n",
      "(5, '0.044*\"self\" + 0.027*\"request\"')\n",
      "(17, '0.042*\"print\" + 0.031*\"line\"')\n",
      "(4, '0.248*\"user\" + 0.057*\"password\"')\n",
      "(14, '0.059*\"table\" + 0.053*\"row\"')\n"
     ]
    }
   ],
   "source": [
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id  AcceptedAnswerId  AnswerCount  \\\n",
      "51  139046            139500            7   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Body  \\\n",
      "51  <p>I need to write code that picks up PGP-encrypted files from an FTP location and processes them. The files will be encrypted with my public key (not that I have one yet). Obviously, I need a PGP library that I can use from within Microsoft Access. Can you recommend one that is easy to use? </p>\\n\\n<p>I'm looking for something that doesn't require a huge amount of PKI knowledge. Ideally, something that will easily generate the one-off private/public key pair, and then have a simple routine ...   \n",
      "\n",
      "   ClosedDate  CommentCount CommunityOwnedDate             CreationDate  \\\n",
      "51        NaN             1                NaN  2008-09-26 12:15:14.317   \n",
      "\n",
      "    FavoriteCount         LastActivityDate LastEditDate LastEditorDisplayName  \\\n",
      "51              1  2010-04-01 01:01:08.450          NaN                   NaN   \n",
      "\n",
      "    LastEditorUserId  OwnerUserId  ParentId  PostTypeId  Score  \\\n",
      "51                 0        21379         0           1      3   \n",
      "\n",
      "                                      Tags  \\\n",
      "51  <security><ms-access><encryption><pgp>   \n",
      "\n",
      "                                                              Title  ViewCount  \n",
      "51  Easiest way to decrypt PGP-encrypted files from VBA (MS Access)      14521  \n",
      "['resolve', 'problem', 'illegal', 'mix', 'collation', 'coercible', 'coercible', 'operation', 'thanks']\n",
      "['video', 'redirect', 'back', 'homepage']\n",
      "[(148, 1), (835, 1), (1986, 1), (2104, 1)]\n",
      "[(5, 0.24069174), (10, 0.19162956), (21, 0.39162102)]\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 500\n",
    "new_doc = df.iloc[[4]]\n",
    "print(new_doc)\n",
    "\n",
    "text = 'when i click on a video, it is redirecting back to homepage, youtube clone'\n",
    "print(tokens)\n",
    "\n",
    "# tokens = prepare_text_for_lda(dict[key]['Body'])\n",
    "tokens = prepare_text_for_lda(text)\n",
    "tokens = removeFirstLastThree(tokens)\n",
    "tokens = toLowerCase(tokens)\n",
    "tokens = removeStopWords(tokens)\n",
    "tokens = applyPStemmer(tokens)\n",
    "tokens = get_lemma(tokens)\n",
    "\n",
    "print(tokens)\n",
    "\n",
    "\n",
    "new_doc_bow = dictionary.doc2bow(tokens)\n",
    "print(new_doc_bow)\n",
    "print(ldamodel.get_document_topics(new_doc_bow))\n",
    "# new_doc_bow = dictionary.doc2bow(new_doc)\n",
    "# print(new_doc_bow)\n",
    "# print(ldamodel.get_document_topics(new_doc_bow))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f67f7bbca0598e70e2d2a4cdc15d594b3c82a687c6c3ba15a4a1d5e50cae4bd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
